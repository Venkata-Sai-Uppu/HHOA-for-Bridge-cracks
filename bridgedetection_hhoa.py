# -*- coding: utf-8 -*-
"""BridgeDetection HHOA

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h9nh-BN9gYFJX1VXOcDKg6P7B9IMYDcB
"""

from google.colab import drive
drive.mount('/content/drive')
import os
os.chdir('/content/drive/My Drive/DataBridge')

import cv2
import numpy as np
# Define the Horse Herd Algorithm function or use a pre-existing implementation
def horse_herd_algorithm(img):
  # Convert the image to grayscale
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

  # Apply Gaussian blur to the image
  blur = cv2.GaussianBlur(gray, (3, 3), 0)

  # Apply Canny edge detection to the image
  edges = cv2.Canny(blur, 30, 100)

  # Apply the Horse Herd Algorithm to the image
  num_iter = 10
  for i in range(num_iter):
      # Calculate the mean and standard deviation of the edge intensities
      mean, std = cv2.meanStdDev(edges)

      # Threshold the image based on the mean and standard deviation
      threshold = int(mean - std)
      ret, thresh = cv2.threshold(edges, threshold, 255, cv2.THRESH_BINARY)

      # Apply a closing operation to the thresholded image
      kernel = np.ones((5,5),np.uint8)
      closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)

      # Update the edges using the closing operation
      edges = cv2.Canny(closing, 30, 100)

  # Find contours in the final edge map
  contours, hierarchy = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

  # Draw the contours on the original image
  cv2.drawContours(img, contours, -1, (0,255,0), 2)

  return img

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

imagesp = []

folder_path = 'Positive'
for filename in os.listdir(folder_path):
    img_path = os.path.join(folder_path, filename)
    print(img_path)
    img = mpimg.imread(img_path)
    imagesp.append(img)

print(len(imagesp))

new_imagesp = []
for img in imagesp:
    new_img = horse_herd_algorithm(img)
    cv2.resize(new_img, (64,64))
    new_imagesp.append(new_img)
new_folder_path = 'Postive_HH'
if not os.path.exists(new_folder_path):
    os.makedirs(new_folder_path)

for i, new_img in enumerate(new_imagesp):
    new_img_path = os.path.join(new_folder_path, f"new_image_{i}.jpg")
    print(new_img_path)
    cv2.imwrite(new_img_path,new_img)

imagesn = []
folder_path = 'Negative'
for filename in os.listdir(folder_path):
    img_path = os.path.join(folder_path, filename)
    print(img_path)
    img = mpimg.imread(img_path)
    imagesn.append(img)

print(len(imagesn))

new_imagesn = []
for img in imagesn:
    new_img = horse_herd_algorithm(img)
    cv2.resize(new_img, (64,64))
    new_imagesn.append(new_img)
new_folder_path = 'Negative_HH'
if not os.path.exists(new_folder_path):
    os.makedirs(new_folder_path)

for i, new_img in enumerate(new_imagesn):
    new_img_path = os.path.join(new_folder_path, f"new_image_{i}.jpg")
    print(new_img_path)
    cv2.imwrite(new_img_path,new_img)

def generate_df(img_dir, label):

    file_paths = pd.Series(list(img_dir.glob(r'*.jpg')), name='Filepath').astype(str)
    print(file_paths[:10])
    print()
    labels = pd.Series(label, name='Label', index=file_paths.index)
    df = pd.concat([file_paths, labels], axis=1)

    return df

from pathlib import Path
from sklearn.model_selection import train_test_split
import tensorflow as tf

positive_dir = Path(r'Postive_HH')
negative_dir = Path(r'Negative_HH')

import pandas as pd
negative_df = generate_df(negative_dir, 'NEGATIVE')
positive_df = generate_df(positive_dir, 'POSITIVE')
# concatenate both positive and negative df
all_df = pd.concat([positive_df, negative_df], axis=0)
all_df

set(all_df['Label'])

train_df, test_df = train_test_split(all_df, train_size=0.8,shuffle=True)
print(train_df.shape, test_df.shape)

train_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,validation_split=0.2)

test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

train_data = train_gen.flow_from_dataframe(train_df,
                                          x_col='Filepath',
                                          y_col='Label',
                                          target_size=(120,120),
                                          color_mode='rgb',
                                          class_mode='binary',
                                          batch_size=32,
                                          shuffle=True,
                                          seed=42,
                                          subset='training')


val_data = train_gen.flow_from_dataframe(train_df,
                                          x_col='Filepath',
                                          y_col='Label',
                                          target_size=(120,120),
                                          color_mode='rgb',
                                          class_mode='binary',
                                          batch_size=32,
                                          shuffle=True,
                                          seed=42,
                                          subset='validation')


test_data = test_gen.flow_from_dataframe(test_df,
                                          x_col='Filepath',
                                          y_col='Label',
                                          target_size=(120,120),
                                          color_mode='rgb',
                                          class_mode='binary',
                                          batch_size=32,
                                          shuffle=False,
                                          seed=42)

inputs = tf.keras.Input(shape=(120,120,3))
x = tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu')(inputs)
x = tf.keras.layers.MaxPool2D(pool_size=(2,2))(x)
x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x)
x = tf.keras.layers.MaxPool2D(pool_size=(2,2))(x)
x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu')(x)
x = tf.keras.layers.MaxPool2D(pool_size=(2,2))(x)

x = tf.keras.layers.GlobalAveragePooling2D()(x)
outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)

model = tf.keras.Model(inputs=inputs, outputs=outputs)

model.compile(optimizer='adam',
             loss='binary_crossentropy',
             metrics=['accuracy'])

# print model summary
model.summary()

history = model.fit(train_data, validation_data=val_data, epochs=3,
                   callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',
                                                              patience=5,
                                                              restore_best_weights=True)
                             ])

model.save("mymodel.h5")

import plotly.express as px
fig = px.line(history.history,
             y=['loss', 'val_loss'],
             labels={'index':'Epoch'},
             title='Training and Validation Loss over Time')

fig.show()

import seaborn as sns

from sklearn.metrics import confusion_matrix, classification_report, r2_score
import numpy as np
def evaluate_model(model, test_data):
    print("testing")
    results = model.evaluate(test_data, verbose=1)
    loss = results[0]
    accuracy = results[1]

    print(f'Test Loss {loss:.5f}')
    print(f'Test Accuracy {accuracy * 100:.2f} %')


    # predicted y values
    y_pred = np.squeeze((model.predict(test_data) >= 0.5).astype(np.int))
    y_certain = np.squeeze((model.predict(test_data)).astype(np.int))

    conf_matr = confusion_matrix(test_data.labels, y_pred)

    class_report = classification_report(test_data.labels, y_pred,
                                         target_names=['NEGATIVE', 'POSITIVE'])

    plt.figure(figsize=(6,6))

    sns.heatmap(conf_matr, fmt='g', annot=True, cbar=False, vmin=0, cmap='Blues')

    plt.xticks(ticks=np.arange(2) + 0.5, labels=['NEGATIVE', 'POSITIVE'])
    plt.yticks(ticks=np.arange(2) + 0.5, labels=['NEGATIVE', 'POSITIVE'])
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title('Confusion Matrix')
    plt.show()

    print('r2 Score : ', r2_score(test_data.labels, y_pred))
    print()
    print('Classification Report :\n......................\n', class_report)

import tensorflow as tf
model = tf.keras.models.load_model("mymodel.h5")
evaluate_model(model, test_data)

import matplotlib.image as mpimg
import numpy as np
import cv2
from PIL import Image

im=Image.open("testimages/p.jpg")
a = mpimg.imread("testimages/p.jpg")
im.show()
a1 = cv2.resize(a,(120,120))
a2 = np.expand_dims(a1, axis=0)
a3 = model.predict(a2)
if a3[0][0]==1:
  print("positive")
else:
  print("negative")

#Image with Crack

b = mpimg.imread("testimages/n.jpg")
im1=Image.open("testimages/n.jpg")
im1.show()
b1 = cv2.resize(b,(120,120))
b2 = np.expand_dims(b1, axis=0)
b3 = model.predict(b2)
if b3[0][0]==1:
  print("positive")
else:
  print("negative")

#Image without Crack